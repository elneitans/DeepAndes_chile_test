{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b8f144",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install matplotlib numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "515e5074",
   "metadata": {},
   "source": [
    "# Geo Analysis Notebook\n",
    "Organized for Colab: loading paths, calculations, display helpers, file utilities, and an analysis runner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "312ec305",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "786abdfb",
   "metadata": {},
   "source": [
    "## Loading Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "509f4ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_json(path: Path):\n",
    "    \"\"\"Load JSON file from a path.\"\"\"\n",
    "    with open(path, \"r\") as file:\n",
    "        return json.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c78041",
   "metadata": {},
   "source": [
    "## Calculation Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f467f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_geos(summary):\n",
    "    \"\"\"Extract class 1 (geo) polygons from summary.\"\"\"\n",
    "    return [polygon for polygon in summary[\"polygons\"] if polygon[\"class\"] == 1]\n",
    "\n",
    "def get_geos_sizes(geos):\n",
    "    \"\"\"Return indexed size and file info for geos.\"\"\"\n",
    "    return [\n",
    "        {\n",
    "            \"index\": geo[\"polygon_index\"],\n",
    "            \"boxmeters\": geo[\"bbox_size_meters\"],\n",
    "            \"shape\": geo[\"image_shape\"],\n",
    "            \"files\": geo[\"files\"],\n",
    "        }\n",
    "        for geo in geos\n",
    "    ]\n",
    "\n",
    "def extract_metrics(geos_sizes):\n",
    "    \"\"\"Extract width, height, and area metrics.\"\"\"\n",
    "    widths = [geo[\"boxmeters\"][\"width_m\"] for geo in geos_sizes]\n",
    "    heights = [geo[\"boxmeters\"][\"height_m\"] for geo in geos_sizes]\n",
    "    areas = [geo[\"boxmeters\"][\"area_m2\"] for geo in geos_sizes]\n",
    "    return widths, heights, areas\n",
    "\n",
    "def _get_axis_limits_with_padding(data_list, padding=0.05):\n",
    "    \"\"\"Return min/max limits with padding for consistent scaling.\"\"\"\n",
    "    flat_data = [val for sublist in data_list for val in sublist]\n",
    "    data_min, data_max = min(flat_data), max(flat_data)\n",
    "    padding_val = (data_max - data_min) * padding\n",
    "    return data_min - padding_val, data_max + padding_val\n",
    "\n",
    "def _remove_outliers_iqr(data, multiplier=1.5):\n",
    "    \"\"\"Remove outliers using the IQR method.\"\"\"\n",
    "    q25, q75 = np.percentile(data, [25, 75])\n",
    "    iqr = q75 - q25\n",
    "    lower_bound = q25 - multiplier * iqr\n",
    "    upper_bound = q75 + multiplier * iqr\n",
    "    return [x for x in data if lower_bound <= x <= upper_bound]\n",
    "\n",
    "def calculate_pixel_scale(geos_sizes):\n",
    "    \"\"\"Calculate mean meters-per-pixel scale for geos.\"\"\"\n",
    "    scales = []\n",
    "    for geo in geos_sizes:\n",
    "        bbox_width = geo[\"boxmeters\"][\"width_m\"]\n",
    "        bbox_height = geo[\"boxmeters\"][\"height_m\"]\n",
    "        img_width = geo[\"shape\"][\"width\"]\n",
    "        img_height = geo[\"shape\"][\"height\"]\n",
    "\n",
    "        width_scale = bbox_width / img_width if img_width > 0 else 0\n",
    "        height_scale = bbox_height / img_height if img_height > 0 else 0\n",
    "        scale = (width_scale + height_scale) / 2\n",
    "        scales.append(scale)\n",
    "\n",
    "    return np.mean(scales) if scales else 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e874746",
   "metadata": {},
   "source": [
    "## Display Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39be74bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_geos_statistics(geos_sizes_list, dataset_names):\n",
    "    \"\"\"Print mean dimensions (outliers removed) and suggested window sizes.\"\"\"\n",
    "    print(\"\\n\" + \"=\" * 90)\n",
    "    print(\"GEO DIMENSIONS STATISTICS (for sliding window determination)\")\n",
    "    print(\"=\" * 90)\n",
    "\n",
    "    for geos_sizes, name in zip(geos_sizes_list, dataset_names):\n",
    "        widths, heights, areas = extract_metrics(geos_sizes)\n",
    "\n",
    "        widths_no_outliers = _remove_outliers_iqr(widths)\n",
    "        heights_no_outliers = _remove_outliers_iqr(heights)\n",
    "        areas_no_outliers = _remove_outliers_iqr(areas)\n",
    "\n",
    "        width_mean = np.mean(widths_no_outliers)\n",
    "        height_mean = np.mean(heights_no_outliers)\n",
    "\n",
    "        scale = calculate_pixel_scale(geos_sizes)\n",
    "\n",
    "        window_size_m = max(int(np.ceil(width_mean)), int(np.ceil(height_mean)))\n",
    "        window_size_px = int(np.ceil(window_size_m / scale)) if scale > 0 else 0\n",
    "\n",
    "        print(f\"\\n{name}:\")\n",
    "        print(f\"  Count:           {len(widths)} (outliers removed from mean calculation)\")\n",
    "        print(f\"  Width:  avg={width_mean:.1f}m  min={min(widths):.1f}m  max={max(widths):.1f}m\")\n",
    "        print(f\"  Height: avg={height_mean:.1f}m  min={min(heights):.1f}m  max={max(heights):.1f}m\")\n",
    "        print(f\"  Area:   avg={np.mean(areas_no_outliers):.1f}m²  min={min(areas):.1f}m²  max={max(areas):.1f}m²\")\n",
    "        print(f\"  Pixel scale: {scale:.4f} m/pixel\")\n",
    "        print(f\"  Suggested sliding window: {window_size_m}m x {window_size_m}m ({window_size_px}px x {window_size_px}px)\")\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 90)\n",
    "\n",
    "def plot_geos_statistics(geos_sizes_list, dataset_names):\n",
    "    \"\"\"Display geo stats text blocks for each dataset.\"\"\"\n",
    "    num_datasets = len(geos_sizes_list)\n",
    "    fig, axes = plt.subplots(1, num_datasets, figsize=(18, 8))\n",
    "    fig.suptitle(\"Geo Dimensions Statistics (for Sliding Window Determination)\", fontsize=16, fontweight=\"bold\")\n",
    "\n",
    "    if num_datasets == 1:\n",
    "        axes = [axes]\n",
    "\n",
    "    for ax, geos_sizes, name in zip(axes, geos_sizes_list, dataset_names):\n",
    "        widths, heights, areas = extract_metrics(geos_sizes)\n",
    "\n",
    "        widths_no_outliers = _remove_outliers_iqr(widths)\n",
    "        heights_no_outliers = _remove_outliers_iqr(heights)\n",
    "        areas_no_outliers = _remove_outliers_iqr(areas)\n",
    "\n",
    "        width_mean = np.mean(widths_no_outliers)\n",
    "        height_mean = np.mean(heights_no_outliers)\n",
    "\n",
    "        scale = calculate_pixel_scale(geos_sizes)\n",
    "        window_size_m = max(int(np.ceil(width_mean)), int(np.ceil(height_mean)))\n",
    "        window_size_px = int(np.ceil(window_size_m / scale)) if scale > 0 else 0\n",
    "\n",
    "        stats_text = f\"{name}\\n\"\n",
    "        stats_text += f\"{'=' * 30}\\n\\n\"\n",
    "        stats_text += f\"Count: {len(widths)}\\n\"\n",
    "        stats_text += f\"(Outliers excluded)\\n\\n\"\n",
    "        stats_text += f\"Width (m):\\n  Avg: {width_mean:.1f}\\n  Min: {min(widths):.1f}\\n  Max: {max(widths):.1f}\\n\\n\"\n",
    "        stats_text += f\"Height (m):\\n  Avg: {height_mean:.1f}\\n  Min: {min(heights):.1f}\\n  Max: {max(heights):.1f}\\n\\n\"\n",
    "        stats_text += f\"Area (m²):\\n  Avg: {np.mean(areas_no_outliers):.1f}\\n  Min: {min(areas):.1f}\\n  Max: {max(areas):.1f}\\n\\n\"\n",
    "        stats_text += f\"Pixel Scale:\\n  {scale:.4f} m/px\\n\\n\"\n",
    "        stats_text += f\"Window Size:\\n  {window_size_m}m × {window_size_m}m\\n  {window_size_px}px × {window_size_px}px\"\n",
    "\n",
    "        ax.axis(\"off\")\n",
    "        ax.text(\n",
    "            0.5,\n",
    "            0.5,\n",
    "            stats_text,\n",
    "            fontsize=10,\n",
    "            family=\"monospace\",\n",
    "            verticalalignment=\"center\",\n",
    "            horizontalalignment=\"center\",\n",
    "            bbox=dict(boxstyle=\"round\", facecolor=\"lightblue\", alpha=0.3, pad=1.5),\n",
    "        )\n",
    "\n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "def plot_distributions(widths, heights, areas, title=\"Distribution of Geo Dimensions\"):\n",
    "    \"\"\"Box plots for widths, heights, and areas.\"\"\"\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "    fig.suptitle(title, fontsize=16)\n",
    "\n",
    "    metrics = [(widths, \"Width (meters)\", 0), (heights, \"Height (meters)\", 1), (areas, \"Area (m²)\", 2)]\n",
    "\n",
    "    for data, label, idx in metrics:\n",
    "        axes[idx].boxplot(data)\n",
    "        axes[idx].set_ylabel(label)\n",
    "        axes[idx].set_title(f\"{label} Distribution\")\n",
    "        axes[idx].grid(True, alpha=0.3)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "def plot_histograms(widths, heights, areas, title=\"Distribution of Geo Dimensions\", bins=20):\n",
    "    \"\"\"Histograms for widths, heights, and areas.\"\"\"\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "    fig.suptitle(title, fontsize=16)\n",
    "\n",
    "    colors = [\"skyblue\", \"lightgreen\", \"lightcoral\"]\n",
    "    metrics = [(widths, \"Width (meters)\", 0), (heights, \"Height (meters)\", 1), (areas, \"Area (m²)\", 2)]\n",
    "\n",
    "    for data, label, idx in metrics:\n",
    "        axes[idx].hist(data, bins=bins, color=colors[idx], edgecolor=\"black\", alpha=0.7)\n",
    "        axes[idx].set_xlabel(label)\n",
    "        axes[idx].set_ylabel(\"Frequency\")\n",
    "        axes[idx].set_title(f\"{label} Distribution\")\n",
    "        axes[idx].grid(True, alpha=0.3, axis=\"y\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "def plot_combined_comparison(datasets, dataset_names, title=\"Comparison of Geo Dimensions Across Datasets\"):\n",
    "    \"\"\"Box plots comparing distributions across datasets with shared scales.\"\"\"\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "    fig.suptitle(title, fontsize=16)\n",
    "\n",
    "    widths_data = [extract_metrics(ds)[0] for ds in datasets]\n",
    "    heights_data = [extract_metrics(ds)[1] for ds in datasets]\n",
    "    areas_data = [extract_metrics(ds)[2] for ds in datasets]\n",
    "\n",
    "    widths_min, widths_max = _get_axis_limits_with_padding(widths_data)\n",
    "    heights_min, heights_max = _get_axis_limits_with_padding(heights_data)\n",
    "    areas_min, areas_max = _get_axis_limits_with_padding(areas_data)\n",
    "\n",
    "    metrics = [\n",
    "        (widths_data, \"Width (meters)\", widths_min, widths_max, 0),\n",
    "        (heights_data, \"Height (meters)\", heights_min, heights_max, 1),\n",
    "        (areas_data, \"Area (m²)\", areas_min, areas_max, 2),\n",
    "    ]\n",
    "\n",
    "    for data, label, y_min, y_max, idx in metrics:\n",
    "        axes[idx].boxplot(data, labels=dataset_names)\n",
    "        axes[idx].set_ylabel(label)\n",
    "        axes[idx].set_title(f\"{label} by Dataset\")\n",
    "        axes[idx].set_ylim(y_min, y_max)\n",
    "        axes[idx].grid(True, alpha=0.3, axis=\"y\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "def plot_single_figure_all_datasets(all_data, dataset_names, title=\"Distribution Comparison\", bins=15):\n",
    "    \"\"\"Histograms for all datasets in one figure with consistent scales.\"\"\"\n",
    "    num_datasets = len(all_data)\n",
    "    fig, axes = plt.subplots(num_datasets, 3, figsize=(18, 5 * num_datasets))\n",
    "    fig.suptitle(title, fontsize=16)\n",
    "\n",
    "    if num_datasets == 1:\n",
    "        axes = axes.reshape(1, -1)\n",
    "\n",
    "    colors = [\"skyblue\", \"lightgreen\", \"lightcoral\"]\n",
    "\n",
    "    all_widths = [width for data in all_data for width in extract_metrics(data)[0]]\n",
    "    all_heights = [height for data in all_data for height in extract_metrics(data)[1]]\n",
    "    all_areas = [area for data in all_data for area in extract_metrics(data)[2]]\n",
    "\n",
    "    widths_min, widths_max = _get_axis_limits_with_padding([all_widths])\n",
    "    heights_min, heights_max = _get_axis_limits_with_padding([all_heights])\n",
    "    areas_min, areas_max = _get_axis_limits_with_padding([all_areas])\n",
    "\n",
    "    for row, (geos_sizes, dataset_name) in enumerate(zip(all_data, dataset_names)):\n",
    "        widths, heights, areas = extract_metrics(geos_sizes)\n",
    "\n",
    "        axes[row, 0].hist(widths, bins=bins, color=colors[0], edgecolor=\"black\", alpha=0.7)\n",
    "        axes[row, 0].set_xlabel(\"Width (meters)\")\n",
    "        axes[row, 0].set_ylabel(\"Frequency\")\n",
    "        axes[row, 0].set_title(f\"{dataset_name} - Width Distribution\")\n",
    "        axes[row, 0].set_xlim(widths_min, widths_max)\n",
    "        axes[row, 0].grid(True, alpha=0.3, axis=\"y\")\n",
    "\n",
    "        axes[row, 1].hist(heights, bins=bins, color=colors[1], edgecolor=\"black\", alpha=0.7)\n",
    "        axes[row, 1].set_xlabel(\"Height (meters)\")\n",
    "        axes[row, 1].set_ylabel(\"Frequency\")\n",
    "        axes[row, 1].set_title(f\"{dataset_name} - Height Distribution\")\n",
    "        axes[row, 1].set_xlim(heights_min, heights_max)\n",
    "        axes[row, 1].grid(True, alpha=0.3, axis=\"y\")\n",
    "\n",
    "        axes[row, 2].hist(areas, bins=bins, color=colors[2], edgecolor=\"black\", alpha=0.7)\n",
    "        axes[row, 2].set_xlabel(\"Area (m²)\")\n",
    "        axes[row, 2].set_ylabel(\"Frequency\")\n",
    "        axes[row, 2].set_title(f\"{dataset_name} - Area Distribution\")\n",
    "        axes[row, 2].set_xlim(areas_min, areas_max)\n",
    "        axes[row, 2].grid(True, alpha=0.3, axis=\"y\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91530aba",
   "metadata": {},
   "source": [
    "## File Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1fbfca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_geos_files_by_area(summary_json_path, source_dir, output_base_dir, area_name):\n",
    "    \"\"\"Copy class-1 geo images and metadata into an area-specific folder.\"\"\"\n",
    "    summary = load_json(summary_json_path)\n",
    "    geos = get_geos(summary)\n",
    "\n",
    "    output_dir = Path(output_base_dir) / area_name\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    source_dir = Path(source_dir)\n",
    "\n",
    "    copied_count = 0\n",
    "    for geo in geos:\n",
    "        polygon_index = geo[\"polygon_index\"]\n",
    "\n",
    "        try:\n",
    "            for filename in geo[\"files\"].values():\n",
    "                source_file = source_dir / filename\n",
    "                if source_file.exists():\n",
    "                    shutil.copy2(source_file, output_dir / filename)\n",
    "\n",
    "            base_name = f\"geoglif_{polygon_index:04d}\"\n",
    "            metadata_file = source_dir / f\"{base_name}_metadata.json\"\n",
    "            if metadata_file.exists():\n",
    "                shutil.copy2(metadata_file, output_dir / f\"{base_name}_metadata.json\")\n",
    "\n",
    "            copied_count += 1\n",
    "        except Exception as exc:\n",
    "            print(f\"Error copying polygon {polygon_index}: {exc}\")\n",
    "\n",
    "    print(f\"Copied {copied_count} geos to {output_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c972ec3d",
   "metadata": {},
   "source": [
    "## Analysis Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f55d373",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_analysis(summaryjson_paths=(\"data/unita/summary.json\", \"data/chug/summary.json\", \"data/lluta/summary.json\"), dataset_labels=(\"UNITA\", \"CHUG\", \"LLUTA\")):\n",
    "    \"\"\"Load summaries, compute sizes, print stats, and plot figures.\"\"\"\n",
    "    summaries = [load_json(path) for path in summaryjson_paths]\n",
    "    geos_list = [get_geos(summary) for summary in summaries]\n",
    "    geos_sizes_list = [get_geos_sizes(geos) for geos in geos_list]\n",
    "\n",
    "    print_geos_statistics(geos_sizes_list, dataset_labels)\n",
    "\n",
    "    figs = {}\n",
    "    figs[\"stats\"] = plot_geos_statistics(geos_sizes_list, dataset_labels)\n",
    "    figs[\"single_fig_all\"] = plot_single_figure_all_datasets(\n",
    "        geos_sizes_list, dataset_labels, \"Geo Dimensions Distribution - All Datasets\"\n",
    "    )\n",
    "    figs[\"combined\"] = plot_combined_comparison(geos_sizes_list, dataset_labels)\n",
    "\n",
    "    plt.show()\n",
    "    return figs, geos_sizes_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b2d47a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute analysis with default datasets\n",
    "run_analysis()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
